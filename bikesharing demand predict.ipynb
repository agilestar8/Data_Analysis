{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. 시간정보를 파싱해서 연,월,일.. 등의 새로운 정보(칼럼) 추가\n- 도움되지않는 월,일,주...등은 제거\n\n\n- day와 month는 오히려 방해하는 요소  why?\n\n> 이유1. day\ntrain set의 날짜는 1-19일의 데이터가 있다, 각각의 카테고리로 인식\ntest set의 날짜는 20-31일의 데이터로 학습, 하지만 day가 겹치지않아 의미있게 쓰지 못했다.\n\n> 이유2. month\n위의 day처럼 train과 test의 값의 분포가 매우 다르다.\ntrain : 월초(1-19)의 data\ntest : 월말(20-31)의 data\n-> month를 추가할 시 안 좋은 학습이 더 과해진다.\n\n> 종합 : tree model은 greedy형으로 학습한다 \n1. 새로운 column이 들어올 시 분포를 보고 가치를 판단\n2. (가치 높을 시) 다른 것들의 학습은 덜하고, 가중치(weight)를 day에게 양보해서 학습시킨다. (파이를 나눠먹는다)\n3. 하지만 막상, train과 test는 day가 겹치지 않아 자원을 낭비함(과적합)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = 100\n\ntrain = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\", parse_dates = [\"datetime\"])\ntrain[\"year\"] = train[\"datetime\"].dt.year\ntrain[\"month\"] = train[\"datetime\"].dt.month\ntrain[\"day\"] = train[\"datetime\"].dt.day\ntrain[\"hour\"] = train[\"datetime\"].dt.hour\ntrain[\"week\"] = train[\"datetime\"].dt.week\ntrain[\"dayofweek\"] = train[\"datetime\"].dt.dayofweek\ntrain[\"week_num\"] = np.ceil(train[\"day\"]/7)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 상관계수보기\n\ntrain.corr()[\"count\"].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.정답값, 필요없는 칼럼 제거\n- datetime은 위에서 새롭게 파싱했으므로 제거\n- casual + registerd = count(정답값)도 전처리해주기","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"year\"].unique())  # 2011, 2012년\nprint(train[\"month\"].unique()) # 1~12월\nprint(train[\"day\"].unique())   # 0~19일\nprint(train[\"hour\"].unique())  # 0~23시","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = train.drop([\"datetime\",\"count\",\"casual\",\"registered\",\"month\",\"week\",\"day\"], axis=1)\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 통계량 추가하기\n\na = train.groupby(\"season\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\na.rename(columns = {\"mean\": \"s_mean\", \"count\": \"s_count\",\"max\":\"s_max\",\"std\":\"s_std\"}, inplace=True)\n\nb = train.groupby(\"holiday\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nb.rename(columns = {\"mean\": \"h_mean\", \"count\": \"h_count\",\"max\":\"h_max\",\"std\":\"h_std\"}, inplace=True)\n\nc = train.groupby(\"workingday\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nc.rename(columns = {\"mean\": \"w_mean\", \"count\": \"w_count\",\"max\":\"w_max\",\"std\":\"w_std\"}, inplace=True)\n\nd = train.groupby(\"weather\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nd.rename(columns = {\"mean\": \"wt_mean\", \"count\": \"wt_count\",\"max\":\"wt_max\",\"std\":\"wt_std\"}, inplace=True)\n\ne = train.groupby(\"hour\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\ne.rename(columns = {\"mean\": \"hr_mean\", \"count\": \"hr_count\",\"max\":\"hr_max\",\"std\":\"hr_std\"}, inplace=True)\n\nf = train.groupby(\"dayofweek\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nf.rename(columns = {\"mean\": \"d_mean\", \"count\": \"d_count\",\"max\":\"d_max\",\"std\":\"d_std\"}, inplace=True)\n\ntrain2 = pd.merge(train2,a,on=\"season\", how='left')\ntrain2 = pd.merge(train2,b,on=\"holiday\", how='left')\ntrain2 = pd.merge(train2,c,on=\"workingday\", how='left')\ntrain2 = pd.merge(train2,d,on=\"weather\", how='left')\ntrain2 = pd.merge(train2,e,on=\"hour\", how='left')\ntrain2 = pd.merge(train2,f,on=\"dayofweek\", how='left')\ntrain2\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  3. test set도 train set과 같이 전처리","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\", parse_dates = [\"datetime\"])\ntest[\"year\"] = test[\"datetime\"].dt.year\n#test[\"month\"] = test[\"datetime\"].dt.month\ntest[\"day\"] = test[\"datetime\"].dt.day\ntest[\"hour\"] = test[\"datetime\"].dt.hour\n#test[\"week\"] = test[\"datetime\"].dt.week\ntest[\"week_num\"] = np.ceil(test[\"day\"]/7)\ntest[\"dayofweek\"] = test[\"datetime\"].dt.dayofweek\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test[\"year\"].unique())  # 2011, 2012년\n# print(test[\"month\"].unique()) # 1~12월\n# print(test[\"day\"].unique())   # 20~31일\nprint(test[\"hour\"].unique())  # 0~23시","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = test.drop([\"datetime\",\"day\"], axis=1)\ntest2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aa = train.groupby(\"season\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\naa.rename(columns = {\"mean\": \"s_mean\", \"count\": \"s_count\",\"max\":\"s_max\",\"std\":\"s_std\"}, inplace=True)\n\nbb = train.groupby(\"holiday\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nbb.rename(columns = {\"mean\": \"h_mean\", \"count\": \"h_count\",\"max\":\"h_max\",\"std\":\"h_std\"}, inplace=True)\n\ncc = train.groupby(\"workingday\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\ncc.rename(columns = {\"mean\": \"w_mean\", \"count\": \"w_count\",\"max\":\"w_max\",\"std\":\"w_std\"}, inplace=True)\n\ndd = train.groupby(\"weather\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\ndd.rename(columns = {\"mean\": \"wt_mean\", \"count\": \"wt_count\",\"max\":\"wt_max\",\"std\":\"wt_std\"}, inplace=True)\n\nee = train.groupby(\"hour\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nee.rename(columns = {\"mean\": \"hr_mean\", \"count\": \"hr_count\",\"max\":\"hr_max\",\"std\":\"hr_std\"}, inplace=True)\n\nff = train.groupby(\"dayofweek\")[\"count\"].agg([\"mean\",\"count\",\"max\",\"std\"])\nff.rename(columns = {\"mean\": \"d_mean\", \"count\": \"d_count\",\"max\":\"d_max\",\"std\":\"d_std\"}, inplace=True)\n\ntest2 = pd.merge(test2,aa,on=\"season\",how=\"left\")\ntest2 = pd.merge(test2,bb,on=\"holiday\",how=\"left\")\ntest2 = pd.merge(test2,cc,on=\"workingday\",how=\"left\")\ntest2 = pd.merge(test2,dd,on=\"weather\",how=\"left\")\ntest2 = pd.merge(test2,ee,on=\"hour\",how=\"left\")\ntest2 = pd.merge(test2,ff,on=\"dayofweek\",how=\"left\")\ntest2\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.시각화\nyear,month,day 등 시간 별 count(정답값)의 그래프보기 ( categorical과 numerical 관계)\n\n1. year-count 그래프 : 연도 별 count차이를 알 수 있고, outlier을 분리해줄 것이 필요\n2. hour-count 그래프 : 시간대 별 count차이를 알 수 있고, 마찬가지로 outlier을 분리해줄 것이 필요\n> - 아침7-8시와 저녁17~18, 22-04시에 많은 경우 : 평일의 출/퇴근, 야근시간 영향으로 유추\n> - 아침~점심(10-16시)에 많은 outlier의 경우 : 주말의 경우로 유추\n\n해주어야할 것 : 평일과 주말의 구분 필요 --> dayofweek(요일)칼럼 추가","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weekday_df = train[train[\"workingday\"]==1] # 평일\nprint(weekday_df.shape)\n\nweekend_df = train[train[\"workingday\"]==0] # 주말\nprint(weekend_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\na,b = plt.subplots(1,1,figsize=(20,12))\nsns.boxplot(train[\"year\"],train[\"count\"])\n\na,b = plt.subplots(1,1,figsize=(20,12))\nsns.boxplot(train[\"hour\"],train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4-2 시각화2\n1. 추가한 dayofweek(요일)-count 그래프 : outlier의 0-4와 5-6의 차이가 나타남 --> 평일,주말의 차이\n\n2. 주말-count 그래프 : 위의 그래프의 outlier를 제대로 나타낸다.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"a,b = plt.subplots(1,1,figsize=(20,12))\nsns.boxplot(train[\"dayofweek\"],train[\"count\"])\n\na,b = plt.subplots(1,1,figsize=(20,12))\nsns.boxplot(weekend_df[\"hour\"],weekend_df[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 정답값 분포보기\n\na,b = plt.subplots(1,1,figsize=(20,12))\nsns.distplot((train[\"count\"]))\n\n# count값의 분포그래프 : 값이 편향되어 있다\n# --> 편향을 막기위해 log를 취해 편향을 해결할 필요가 있다.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.distplot((np.log(train[\"count\"])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. 머신러닝 모델 설계\n\nbagging방식의 RandomForestRegressor로 데이터셋에 맞는 hyperparameter를 대략적으로 맞추고 baseline을 잡는다.\n\n> - 통계량 feature를 추가하면서 columns이 많이 증가하고, 그로인해 bagging의 효율이 떨어져 baseline잡는데 어려움을 겪음\n\n대신 robust한 catboost model로 baseline을 잡는다.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 결측치 처리\ntrain2 = train2.fillna(-1)\ntest2 = test2.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n# rf = RandomForestRegressor(n_estimators = 100, n_jobs = 4, random_state = 1)\n# rf.fit(train2,np.log(train[\"count\"]))\n# result = rf.predict(test2)\n\nfrom catboost import CatBoostRegressor\nca = CatBoostRegressor(iterations = 1000)\nca.fit(train2,np.log(train[\"count\"]))\nresult1 = ca.predict(test2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 학습변수중요도 확인\n- 각 칼럼의 학습된 정도를 확인가능 --> 중요도 확인가능","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(ca.feature_importances_,index = train2.columns).sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. 제출","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/bike-sharing-demand/sampleSubmission.csv\")\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[\"count\"] = np.exp(result)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"sub.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}